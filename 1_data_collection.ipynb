{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping and Pose capture from annotations\n",
    "The following script sets out steps for scraping the videos and then capturing the pose data from them using the annotaion files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionaries of the 2019 recording links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "men_video_links = {\n",
    "\"109+\":\"https://www.youtube.com/watch?v=lEriREH2eVs\",\n",
    "\"109\":\"https://www.youtube.com/watch?v=pcDOw9RkmbM\",\n",
    "\"102\":\"https://www.youtube.com/watch?v=VDrDUh-ZIXE\",\n",
    "\"96\":\"https://www.youtube.com/watch?v=PdYtEusK4I8\",\n",
    "\"89\":\"https://www.youtube.com/watch?v=D-JPFuKovcU\",\n",
    "\"81\":\"https://www.youtube.com/watch?v=8nfA8rAfHSI\",\n",
    "\"73\":\"https://www.youtube.com/watch?v=34JJ12OOpng\",\n",
    "\"67\":\"https://www.youtube.com/watch?v=0gGjCEcBG_I\",\n",
    "\"61\":\"https://www.youtube.com/watch?v=plFZt23A-Fk\",\n",
    "\"55\":\"https://www.youtube.com/watch?v=mlAht5v2Uvo\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Download and Rename all the recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.the-analytics.club/download-youtube-videos-in-python/\n",
    "# Step I: Install Pytube using pip\n",
    "\n",
    "# Step II : In your script import the YouTube class from pytube package.\n",
    "from pytube import YouTube\n",
    "from os import getcwd as wd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def download_yt_videos(video_url:str,folder_path:str):\n",
    "    \"\"\"\n",
    "    The function downloads a video stream to a folder path\n",
    "    \"\"\"\n",
    "    # Step III : Create an object of YouTube, by passing the video URL\n",
    "    yt = YouTube(video_url)\n",
    "    # Step IV : Use the filter method to specify the download format of the video\n",
    "    mp4_files = yt.streams.filter(file_extension=\"mp4\")\n",
    "    # Step V : Get the video you want by specifying the resolution\n",
    "    mp4_down_files = mp4_files.get_by_resolution(\"720p\")\n",
    "    # Step VI : Save the downloaded video to the local file system\n",
    "    mp4_down_files.download(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path_men = f\"{wd()}/data/videos/men\"\n",
    "\n",
    "for item in men_video_links:\n",
    "    download_yt_videos(men_video_links[item],folder_path_men)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rename the videos in the folder (original names are the full video titles)\n",
    " - Get list of the files in the folder\n",
    " - For item in the folder look if the name contains the weight string.\n",
    " - save the file in the folder with a simple name string with weight in the tittle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109\n",
      "109+\n"
     ]
    }
   ],
   "source": [
    "def rename_files_in_folder(folder_path:str,\n",
    "                        new_names_list:str,\n",
    "                        addiional_str:str):\n",
    "    \"\"\"\n",
    "    Function renames the filenames of the downloaded videos    \n",
    "    \"\"\"\n",
    "\n",
    "    files_list = os.listdir(folder_path)\n",
    "    for file_name in files_list:\n",
    "        for name in new_names_list:\n",
    "            if f\"{name}kg\" in file_name:\n",
    "                print(name)\n",
    "                original_file_name = \"{}/{}\".format(folder_path,file_name)\n",
    "                updated_file_name = \"{}/{}{}.mp4\".format(folder_path,name,addiional_str)\n",
    "                os.rename(original_file_name,updated_file_name)\n",
    "\n",
    "\n",
    "rename_files_in_folder(folder_path_men,men_video_links.keys(),\"_men_2019\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Create the folder structure\n",
    " - annotation files\n",
    " - name files\n",
    " - initial data pose files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import csv\n",
    "\n",
    "def create_csv_in_path(name_str,folder_path,columns,add_date = True):\n",
    "    \"\"\"\n",
    "    Create a csv file with columns\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create name with date\n",
    "    if add_date:\n",
    "        csv_path = \"{}/{}_{}.csv\".format(\n",
    "            folder_path,name_str,datetime.datetime.now().strftime(\"%Y_%m_%d__%H_%M\"))\n",
    "    else:\n",
    "        csv_path = \"{}/{}.csv\".format(folder_path,name_str)\n",
    "\n",
    "\n",
    "    with open(csv_path, mode='x', newline='') as f:\n",
    "        csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        csv_writer.writerow(columns)\n",
    "\n",
    "    # Check if the line was written to the file\n",
    "    bash_command = \"cat {}\".format(csv_path)    \n",
    "    os.system(bash_command)\n",
    "\n",
    "    return csv_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create annotation csv files.\n",
    "columns = [\n",
    "    \"name\",\n",
    "    \"weight\",\n",
    "    \"lift_start\",\n",
    "    \"lift_end\",    \n",
    "    \"success\"\n",
    "]\n",
    "\n",
    "for name in men_video_links.keys():\n",
    "    create_csv_in_path(\"{}_annot\".format(name),folder_path_men,columns,False)\n",
    "\n",
    "# Create name csv files.\n",
    "columns = [\"name\",\"country\"]\n",
    "\n",
    "for name in men_video_links.keys():\n",
    "    create_csv_in_path(\"{}_name\".format(name),folder_path_men,columns,False)\n",
    "\n",
    "# Create pose csv's\n",
    "columns = [\n",
    "    \"id\",\n",
    "    \"class\",\n",
    "    \"time_ms\",\n",
    "    \"success\",\n",
    "    \"weightclass\",\n",
    "    \"name\",\n",
    "    \"country\",\n",
    "    \"weight\"\n",
    "]\n",
    "columns\n",
    "\n",
    "select_features = [f'{dimension}{item}' for item in range(33) for dimension in [\"x\",\"y\",\"z\",\"v\"]]\n",
    "\n",
    "columns.extend(select_features)\n",
    "columns\n",
    "\n",
    "for name in men_video_links.keys():\n",
    "    create_csv_in_path(\"{}_pose\".format(name),folder_path_men,columns,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Process annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Read the annotation file.\n",
    " - Read the name file.\n",
    " - Create combined csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dictionanries with paths to different files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_list = os.listdir(folder_path_men)\n",
    "df_name_path = {}\n",
    "df_annotations_path = {}\n",
    "df_pose_path = {}\n",
    "df_video_path = {}\n",
    "df_combined_path = {}\n",
    "\n",
    "\n",
    "for weight in men_video_links.keys():\n",
    "    for item in files_list:\n",
    "        if \"{}_\".format(weight) in item:\n",
    "            if \"name\" in item:\n",
    "                df_name_path[weight] = \"{}/{}\".format(folder_path_men,item)\n",
    "                # print(df_name_path)\n",
    "            elif \"annot\" in item:\n",
    "                df_annotations_path[weight] = \"{}/{}\".format(folder_path_men,item)\n",
    "                # print(df_annotations_path)\n",
    "            elif \"pose\" in item:\n",
    "                df_pose_path[weight] = \"{}/{}\".format(folder_path_men,item)\n",
    "                # print(df_pose_path)\n",
    "            elif \"mp4\" in item:\n",
    "                df_video_path[weight] = \"{}/{}\".format(folder_path_men,item)\n",
    "                # print(df_video_path)\n",
    "            \n",
    "    df_combined_path[weight] = \"{}/men/{}_combined.csv\".format(folder_path_men,weight)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a combined dataframe with corrected times to seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sec(time_str):\n",
    "    \"\"\"Get seconds from time.\"\"\"\n",
    "    h, m, s = time_str.split(':')\n",
    "    return int(h) * 3600 + int(m) * 60 + int(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28,TALAKHADZE,GEO,220,2745,2748,1\n",
      "29,MARTIROSYAN,ARM,199,2693,2698,1\n",
      "35,JIN,KOR,183,2569,2574,0\n",
      "32,RIVAS,COL,182,3037,3039,0\n",
      "29,DAVITADZE,GEO,172,2365,2369,1\n",
      "29,KARAPETYAN,ARM,172,2333,2335,0\n",
      "28,SHIZ,CHN,166,2735,2739,1\n",
      "32,ISMAYILOV,TUR,154,2673,2675,0\n",
      "33,LI,CHN,145,2848,2851,1\n",
      "23,OM,PRK,128,2111,2113,1\n"
     ]
    }
   ],
   "source": [
    "for category in men_video_links.keys(): \n",
    "    df_name = pd.read_csv(df_name_path[category])\n",
    "    # Get the annotations\n",
    "    df_annotations = pd.read_csv(df_annotations_path[category])\n",
    "\n",
    "    #!!!!!!! Insert athletes names and countries !!!!!!!\n",
    "\n",
    "    # Insert an extra coulumn to be replaced by the country name\n",
    "    df_annotations.insert(1,\"country\",df_annotations[\"name\"])\n",
    "    # Insert the Names of athletes\n",
    "    df_annotations[\"name\"] = df_annotations[\"name\"].apply(lambda x:df_name[\"name\"][x-1])\n",
    "    # Insert the countries of athletes\n",
    "    df_annotations[\"country\"] = df_annotations[\"country\"].apply(lambda x:df_name[\"country\"][x-1])\n",
    "\n",
    "    #!!!!!!! Correct the time format in the dataframe !!!!!!!\n",
    "    df_annotations[\"lift_start\"] = df_annotations[\"lift_start\"].apply(get_sec)\n",
    "    df_annotations[\"lift_end\"] = df_annotations[\"lift_start\"] + df_annotations[\"lift_end\"]\n",
    "\n",
    "    df_annotations.head()\n",
    "\n",
    "    uf.save_df_to_csv(df_annotations,df_combined_path[category])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Process pose for the annotations collected\n",
    "Using mediapipe pose detector, capture the pose data for each weight category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 # Import opencv\n",
    "import mediapipe as mp # Import mediapipe\n",
    "# Import the pose capture methods from mediapipe\n",
    "mp_drawing = mp.solutions.drawing_utils # Drawing helpers\n",
    "mp_pose = mp.solutions.pose # Mediapipe Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_and_save_pose(category, total_index):\n",
    "    print(\"Processing {} weight category!\".format(category))\n",
    "    cap = cv2.VideoCapture(df_video_path[category]) # Using video file\n",
    "    df = pd.read_csv(df_combined_path[category],index_col=0)\n",
    "    \n",
    "    start_set = False\n",
    "    list_index = 0\n",
    "    index_list = df.index.to_list()\n",
    "    len_of_list = df.shape[0]\n",
    "    \n",
    "    # Initiate holistic model\n",
    "    with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "        \n",
    "        while cap.isOpened():\n",
    "\n",
    "                if not start_set:\n",
    "                    start_time_ms = df.loc[index_list[list_index]][\"lift_start\"] * 1000\n",
    "                    end_time_ms = df.loc[index_list[list_index]][\"lift_end\"] * 1000\n",
    "                    cap.set(cv2.CAP_PROP_POS_MSEC,start_time_ms)\n",
    "                    start_set = not start_set\n",
    "                \n",
    "                current_time_ms = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "\n",
    "                if current_time_ms >= end_time_ms:\n",
    "                    start_set = not start_set\n",
    "                    list_index += 1\n",
    "                    total_index += 1\n",
    "                    if list_index >= len_of_list: break\n",
    "                    continue\n",
    "                \n",
    "                success, frame = cap.read()\n",
    "\n",
    "\n",
    "                if not success:\n",
    "                    print(\"Camera frame empty!\")\n",
    "                    # continue # if webcam stream\n",
    "                    break # if video stream\n",
    "                \n",
    "                # Going from 1080x1920p\n",
    "                # Resize to 3600x640p (width, height) same aspect ratio\n",
    "                # im_resized = cv2.resize(frame,(360,640))\n",
    "\n",
    "                # Recolor Feed\n",
    "                # image = cv2.cvtColor(im_resized, cv2.COLOR_BGR2RGB)\n",
    "                image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                image.flags.writeable = False        \n",
    "                \n",
    "                # Make Detections\n",
    "                results = pose.process(image)\n",
    "\n",
    "\n",
    "                # Export coordinates\n",
    "                try:\n",
    "                    # Extract Pose landmarks\n",
    "                    # pose_results = results.pose_world_landmarks.landmark # world landmarks - distances in meeters\n",
    "                    pose_results = results.pose_landmarks.landmark # Normalised landmarks - distances [0,1]\n",
    "                    # pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n",
    "                    pose_row = np.array([[item.x, item.y, item.z, item.visibility] for item in pose_results]).flatten().tolist()\n",
    "                    \n",
    "                    \n",
    "                    # Append class name \n",
    "                    pose_row.insert(0, total_index)\n",
    "                    pose_row.insert(1, \"other\")\n",
    "                    pose_row.insert(2, current_time_ms)\n",
    "                    pose_row.insert(3, df.loc[index_list[list_index]][\"success\"])\n",
    "                    pose_row.insert(4, category)\n",
    "                    pose_row.insert(5, df.loc[index_list[list_index]][\"name\"])\n",
    "                    pose_row.insert(6, df.loc[index_list[list_index]][\"country\"])\n",
    "                    pose_row.insert(7, df.loc[index_list[list_index]][\"weight\"])\n",
    "\n",
    "\n",
    "                    # Export to CSV\n",
    "                    with open(df_pose_path[category], mode='a', newline='') as f:\n",
    "                        csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                        csv_writer.writerow(pose_row) \n",
    "                    \n",
    "                except Exception as e:\n",
    "                    # print(\"Can't extract line\") \n",
    "                    # print(e)\n",
    "                    pass\n",
    "\n",
    "\n",
    "\n",
    "                # Recolor image back to BGR for rendering\n",
    "                image.flags.writeable = True   \n",
    "                image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "                \n",
    "                \n",
    "                # Draw Pose Detections\n",
    "                mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS, \n",
    "                                        mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                        mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                                        )\n",
    "                                \n",
    "                cv2.imshow('Raw Webcam Feed', image)\n",
    "            \n",
    "                # Stop playing\n",
    "                if (cv2.waitKey(1) & 0xFF == ord('q')):\n",
    "                    input_value = input(\"What?\")\n",
    "                    if input_value == \"q\": break\n",
    "                    if input_value == \"p\": \n",
    "                        print(pose_row)\n",
    "                        continue\n",
    "\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"Done! Total idx = {}\".format(total_index))\n",
    "    return total_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 109+ weight category!\n",
      "Done! Total idx = 29\n",
      "Processing 109 weight category!\n",
      "Done! Total idx = 59\n",
      "Processing 102 weight category!\n",
      "Done! Total idx = 95\n",
      "Processing 96 weight category!\n",
      "Done! Total idx = 128\n",
      "Processing 89 weight category!\n",
      "Done! Total idx = 158\n",
      "Processing 81 weight category!\n",
      "Done! Total idx = 188\n",
      "Processing 73 weight category!\n",
      "Done! Total idx = 217\n",
      "Processing 67 weight category!\n",
      "Done! Total idx = 250\n",
      "Processing 61 weight category!\n",
      "Done! Total idx = 284\n",
      "Processing 55 weight category!\n",
      "Done! Total idx = 308\n"
     ]
    }
   ],
   "source": [
    "total_idx = 0\n",
    "for category in men_video_links.keys():\n",
    "    total_idx = capture_and_save_pose(category,total_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine all the data into a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30266, 140)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames = []\n",
    "for category in men_video_links.keys():\n",
    "    df = pd.read_csv(df_pose_path[category])\n",
    "    frames.append(df)\n",
    "\n",
    "df = pd.concat(frames)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the final collected dataframe to a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import util\n",
    "util.save_df_to_csv(df,f\"{wd()}/data/combined_captured_pose_dataframe.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "137b24a0fe882e03497aebb440db419c28977b60c691207d253f88f6220e2448"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('msc-proj-env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
